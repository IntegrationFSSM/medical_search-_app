"""
Service pour la recherche de pathologies bas√©e sur les embeddings OpenAI
"""
import numpy as np
from pathlib import Path
import json
from openai import OpenAI
from django.conf import settings


class PathologySearchService:
    """Service de recherche de pathologies m√©dicales via embeddings."""
    
    def __init__(self):
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
        self.embedding_model = settings.EMBEDDING_MODEL
        self.embeddings_folder = settings.EMBEDDINGS_FOLDER
    
    def validate_medical_query(self, query):
        """
        Valider si une requ√™te est une description m√©dicale valide en utilisant GPT-4o.
        
        Args:
            query: Texte de la requ√™te √† valider
            
        Returns:
            dict: {
                'is_valid': bool,
                'reason': str (si non valide)
            }
        """
        try:
            prompt = f"""Tu es un validateur m√©dical. Analyse la requ√™te suivante et d√©termine si elle contient un r√©el contenu m√©dical OU du texte sans sens.

Requ√™te: "{query}"

ACCEPTE (is_valid = true) si la requ√™te:
- Mentionne des sympt√¥mes, troubles, comportements ou conditions m√©dicales
- D√©crit une situation clinique (m√™me simple)
- Est li√©e √† la sant√© mentale ou comportementale
- Contient des mots fran√ßais/anglais normaux avec du sens m√©dical
- Exemples VALIDES: "homme alcoolique", "enfant anxieux", "troubles du sommeil", "d√©pression", "patient agressif"

REJETTE (is_valid = false) SEULEMENT si:
- Mots r√©p√©titifs sans sens: "blabla blabla", "test test test", "aaaa aaaa"
- Uniquement des symboles: ".....", "????", "!!!!"
- Mots al√©atoires sans rapport m√©dical: "voiture maison arbre"
- Texte incoh√©rent ou spam √©vident

IMPORTANT: Si la requ√™te mentionne un terme m√©dical/psychologique r√©el (m√™me court), accepte-la !

R√©ponds UNIQUEMENT par un JSON:
{{
    "is_valid": true/false,
    "reason": "Explication courte si non valide (sinon null)"
}}"""

            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Tu es un validateur m√©dical expert. R√©ponds uniquement en JSON."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=200
            )
            
            result_text = response.choices[0].message.content.strip()
            print(f"üîç Validation GPT-4o response: {result_text}")
            
            # Extraire le JSON si le texte contient du texte avant/apr√®s
            import json
            import re
            
            # Essayer de trouver un JSON dans le texte
            json_match = re.search(r'\{[^}]*"is_valid"[^}]*\}', result_text)
            if json_match:
                result_text = json_match.group(0)
            
            result = json.loads(result_text)
            
            is_valid = result.get('is_valid', False)
            reason = result.get('reason', 'Requ√™te invalide')
            
            print(f"‚úÖ Validation result: is_valid={is_valid}, reason={reason}")
            
            return {
                'is_valid': is_valid,
                'reason': reason
            }
            
        except json.JSONDecodeError as e:
            print(f"‚ùå Erreur JSON parsing: {e}")
            print(f"‚ùå Response text: {result_text}")
            # En cas d'erreur de parsing, consid√©rer comme invalide par s√©curit√©
            return {
                'is_valid': False,
                'reason': 'Erreur de validation - veuillez r√©essayer'
            }
        except Exception as e:
            print(f"‚ùå Erreur validation GPT: {e}")
            # En cas d'erreur API, consid√©rer comme invalide par s√©curit√©
            return {
                'is_valid': False,
                'reason': 'Service de validation temporairement indisponible'
            }
    
    def get_embedding(self, text):
        """Obtenir l'embedding d'un texte via l'API OpenAI."""
        text = text.replace("\n", " ")
        response = self.client.embeddings.create(
            input=[text], 
            model=self.embedding_model
        )
        return np.array(response.data[0].embedding)
    
    def find_best_match(self, query, top_k=5, aggregation='max'):
        """
        Trouver les meilleurs fichiers correspondant √† une requ√™te.
        
        Args:
            query: Requ√™te texte
            top_k: Nombre de r√©sultats √† retourner
            aggregation: M√©thode d'agr√©gation ('max', 'mean', 'weighted_mean')
        
        Returns:
            Liste des meilleurs r√©sultats avec scores de similarit√©
        """
        import os
        folder_path = Path(self.embeddings_folder)
        
        # Debug: afficher les informations
        print(f"üîç DEBUG: embeddings_folder configur√© = {self.embeddings_folder}")
        print(f"üîç DEBUG: folder_path = {folder_path}")
        print(f"üîç DEBUG: folder_path absolu = {folder_path.absolute()}")
        print(f"üîç DEBUG: folder_path existe? = {folder_path.exists()}")
        print(f"üîç DEBUG: r√©pertoire courant = {os.getcwd()}")
        
        # Lister le contenu du r√©pertoire parent
        try:
            parent = folder_path.parent
            print(f"üîç DEBUG: contenu de {parent}:")
            for item in os.listdir(parent):
                print(f"  - {item}")
        except Exception as e:
            print(f"‚ùå DEBUG: Erreur lors du listage: {e}")
        
        if not folder_path.exists():
            return {
                'success': False,
                'error': f"Le dossier d'embeddings n'existe pas: {self.embeddings_folder} (chemin absolu: {folder_path.absolute()})",
                'results': []
            }
        
        # Rechercher les fichiers .npy
        npy_files = list(folder_path.rglob("*.npy"))
        
        if len(npy_files) == 0:
            return {
                'success': False,
                'error': "Aucun fichier d'embedding trouv√© (.npy)",
                'results': []
            }
        
        # Obtenir l'embedding de la requ√™te
        query_embedding = self.get_embedding(query)
        
        # Rechercher dans tous les fichiers
        file_results = {}
        
        for emb_file in npy_files:
            # Charger les embeddings
            embeddings = np.load(emb_file)
            
            # Charger les m√©tadonn√©es
            metadata_file = str(Path(emb_file).with_suffix('.json'))
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
            except:
                continue
            
            # Calculer la similarit√© cosinus pour chaque chunk
            chunk_similarities = []
            best_chunk_id = 0
            best_chunk_text = ""
            best_similarity = 0
            
            for i, chunk_emb in enumerate(embeddings):
                similarity = np.dot(query_embedding, chunk_emb) / (
                    np.linalg.norm(query_embedding) * np.linalg.norm(chunk_emb)
                )
                chunk_similarities.append(similarity)
                
                if similarity > best_similarity:
                    best_similarity = similarity
                    best_chunk_id = i
                    best_chunk_text = metadata['chunks'][i].get('text_preview', '')
            
            # Agr√©ger les scores par fichier
            if aggregation == 'max':
                file_score = max(chunk_similarities)
            elif aggregation == 'mean':
                file_score = np.mean(chunk_similarities)
            elif aggregation == 'weighted_mean':
                weights = np.array([1.0 / (i + 1) for i in range(len(chunk_similarities))])
                weights = weights / weights.sum()
                file_score = np.sum(np.array(chunk_similarities) * weights)
            else:
                file_score = max(chunk_similarities)
            
            file_results[str(emb_file)] = {
                'file': metadata['source_file'],
                'file_name': Path(metadata['source_file']).name,
                'location': metadata['hierarchy'].get('location', 'N/A'),
                'similarity': float(file_score),
                'num_chunks': len(embeddings),
                'best_chunk_id': best_chunk_id,
                'best_chunk_text': best_chunk_text,
                'all_chunk_scores': [float(s) for s in chunk_similarities],
                'html_page': metadata.get('html_page', '')  # Ajouter le chemin HTML
            }
        
        # Trier par similarit√©
        results = sorted(
            file_results.values(), 
            key=lambda x: x['similarity'], 
            reverse=True
        )[:top_k]
        
        # V√©rifier la qualit√© des r√©sultats - seuil minimum de 60% (plus strict)
        if not results or results[0]['similarity'] < 0.6:
            return {
                'success': False,
                'error': 'Aucune correspondance trouv√©e. Veuillez v√©rifier que votre description est compl√®te et pr√©cise.',
                'error_type': 'low_similarity',
                'best_score': results[0]['similarity'] * 100 if results else 0,
                'results': []
            }
        
        # Ajouter des informations diagnostiques
        diagnostic_info = self._generate_diagnostic_info(results)
        
        return {
            'success': True,
            'results': results,
            'diagnostic_info': diagnostic_info,
            'total_files_searched': len(file_results)
        }
    
    def _generate_diagnostic_info(self, results):
        """G√©n√©rer des informations diagnostiques bas√©es sur les r√©sultats."""
        if not results:
            return {
                'suspected_pathology': None,
                'confidence': 0,
                'confidence_level': 'none'
            }
        
        top_match = results[0]
        similarity_percent = top_match['similarity'] * 100
        
        pathology = top_match['file_name'].replace('.txt', '').replace('_', ' ')
        
        if similarity_percent >= 75:
            confidence_level = 'high'
            message = "Forte correspondance diagnostique"
        elif similarity_percent >= 60:
            confidence_level = 'moderate'
            message = "Correspondance mod√©r√©e - Envisager un diagnostic diff√©rentiel"
        else:
            confidence_level = 'low'
            message = "Faible confiance - Informations cliniques suppl√©mentaires n√©cessaires"
        
        return {
            'suspected_pathology': pathology,
            'confidence': similarity_percent,
            'confidence_level': confidence_level,
            'message': message
        }
    
    def generate_ai_diagnosis(self, pathology_name, form_data, similarity_score, medical_text="", historical_symptoms=None):
        """
        G√©n√©rer un r√©sum√© diagnostique structur√© (sans plan de traitement) avec OpenAI
        bas√© sur les donn√©es du formulaire, le texte m√©dical et l'historique.
        
        Args:
            pathology_name: Nom de la pathologie valid√©e
            historical_symptoms: Liste des sympt√¥mes/crit√®res des consultations pr√©c√©dentes (optionnel)
            form_data: Donn√©es du formulaire (dict avec tous les crit√®res coch√©s)
            similarity_score: Score de similarit√© de la recherche
            medical_text: Texte m√©dical extrait du fichier source (documentation DSM-5-TR)
        
        Returns:
            dict: Plan de traitement g√©n√©r√© par l'IA
        """
        try:
            # Construire le prompt pour OpenAI avec le texte m√©dical et l'historique
            prompt = self._build_diagnosis_prompt(pathology_name, form_data, similarity_score, medical_text, historical_symptoms)
            
            # Appeler OpenAI GPT-4
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "Vous √™tes un psychiatre clinicien expert du DSM-5-TR. "
                            "Vous r√©digez des r√©sum√©s diagnostiques structur√©s et concis en fran√ßais, "
                            "en citant uniquement les crit√®res r√©ellement coch√©s. "
                            "INTERDIT : prescrire ou d√©tailler un plan de traitement ou des posologies."
                        )
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.4,
                max_tokens=1800
            )
            
            diagnosis_text = response.choices[0].message.content
            
            return {
                'success': True,
                'pathology': pathology_name,
                'diagnosis': diagnosis_text,
                'confidence': similarity_score,
                'timestamp': self._get_timestamp()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'pathology': pathology_name
            }
    
    def _build_diagnosis_prompt(self, pathology_name, form_data, similarity_score, medical_text="", historical_symptoms=None):
        """Construire le prompt pour OpenAI avec le texte m√©dical et l'historique du patient."""
        
        prompt = f"""√âlabore un R√âSUM√â DIAGNOSTIQUE (sans plan th√©rapeutique) pour un patient √©valu√© selon le DSM-5-TR.

Consignes obligatoires :
- Baser l'analyse UNIQUEMENT sur les crit√®res coch√©s ci-dessous et sur l'extrait m√©dical fourni.
- Ne jamais prescrire ni d√©crire un traitement m√©dicamenteux ou une posologie.
- Utiliser un ton clinique, structur√© et concis en fran√ßais.

Informations de r√©f√©rence :
‚Ä¢ Pathologie suspect√©e : {pathology_name}
‚Ä¢ Niveau de correspondance : {similarity_score:.1f}%

Extrait DSM-5-TR disponible :
{medical_text if medical_text else "Aucun extrait suppl√©mentaire. S'appuyer uniquement sur les crit√®res coch√©s."}

Crit√®res et √©l√©ments cliniques d√©clar√©s :
"""
        
        # üÜï AJOUTER L'HISTORIQUE M√âDICAL
        if historical_symptoms and len(historical_symptoms) > 0:
            prompt += f"\nüìã **ANT√âC√âDENTS M√âDICAUX DU PATIENT ({len(historical_symptoms)} sympt√¥mes enregistr√©s):**\n"
            prompt += "Le patient pr√©sente √©galement les ant√©c√©dents cliniques suivants, issus de consultations pr√©c√©dentes:\n"
            for i, symptom in enumerate(historical_symptoms[:15], 1):  # Limiter √† 15 pour ne pas surcharger
                prompt += f"  ‚Ä¢ {symptom}\n"
            if len(historical_symptoms) > 15:
                prompt += f"  ‚Ä¢ ... et {len(historical_symptoms) - 15} autres sympt√¥mes enregistr√©s\n"
            prompt += "\n**‚ö†Ô∏è IMPORTANT : Int√©grer ces ant√©c√©dents dans l'analyse diagnostique.**\n\n"
        
        prompt += """
"""
        
        # Ajouter les donn√©es du formulaire
        if isinstance(form_data, dict):
            for key, value in form_data.items():
                if value:  # Si la valeur n'est pas vide
                    if isinstance(value, list):
                        prompt += f"\n**{key}:**\n"
                        for item in value:
                            prompt += f"  ‚úì {item}\n"
                    else:
                        prompt += f"\n**{key}:** {value}\n"
        
        prompt += """

Structure attendue (respecter EXACTEMENT ces titres) :

## 1. Synth√®se clinique
- 2 √† 3 phrases r√©sumant la pr√©sentation clinique et le niveau de confiance.

## 2. Crit√®res DSM-5 confirm√©s
- Reprendre les crit√®res coch√©s (par blocs si possible) avec le nombre total valid√©.

## 3. Diagnostic diff√©rentiel prioritaire
- 3 √† 5 hypoth√®ses maximum, chacune justifi√©e bri√®vement.

## 4. Comorbidit√©s / facteurs associ√©s
- √âl√©ments issus du formulaire ou traditionnellement li√©s √† la pathologie, avec lien clinique.

## 5. Recommandations cliniques imm√©diates
- √âtapes de suivi, examens compl√©mentaires, coordination interdisciplinaire ou psycho√©ducation.
- INTERDIT : citer des mol√©cules, dosages, ou protocoles th√©rapeutiques.
"""
        
        return prompt
    
    def _get_timestamp(self):
        """Obtenir le timestamp actuel."""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

